
<h1>
  <img src="asset/logo.svg" alt="logo" style="height: 1.5em; vertical-align: bottom;" />
  GLM-CookBook
</h1>

[é˜…è¯»ä¸­æ–‡ç‰ˆ](README.zh.md)

Welcome to the GLM API Beginnerâ€™s Repository ðŸ“˜. This is an open-source tutorial book of introductory code for the GLM API.

## Updates ðŸ”¥

+ ðŸ”¥ GLM-4.5 is now integrated with Claude Code, see [GLM-4.5 Claude Code Integration Guide](vibecoding/glm-4.5-claude-code-integration.md).

## Quick Start ðŸš€

1. Install dependencies

```bash
pip install -r requirements.txt
```

1. Configure your [Z.AI](https://z.ai/model-api) account, or your [openrouter](https://openrouter.ai/settings/keys) account.

## Repository Structure ðŸ“‚

We have categorized multiple folders, each containing their own content. You can check them out according to your needs!

+ `basic` The most fundamental content to help you get familiar with basic API calls.

+ `vision` API calls related to vision models and drawing models.

+ `vibecoding` Examples of using the GLM series models for code development.

+ `finetune` Fine-tuning GLM models.

+ `demo` Some fun little projects that might inspire you.
  + `agent` See how powerful the conference demo agent is!
  + `data` Data required to run the demos.

+ `asset` Some related image materials.

You can quickly understand the structure of this repository through the image below. I will update the latest experiments and teaching content of the Zhipu AI SDK as soon as possible.

![Architecture Diagram](asset/plan.png)

## SDK Open Source ðŸ”§

The Z.AI SDK is now open source. If you want to directly modify our SDK, you can do so at the following repositories:

+ [Python SDK](https://github.com/MetaGLM/zhipuai-sdk-python-v4)
+ [Java SDK](https://github.com/MetaGLM/zhipuai-sdk-java-v4)
+ [C# SDK](https://github.com/MetaGLM/zhipuai-sdk-csharp-v4)
+ [Node.js SDK](https://github.com/MetaGLM/zhipuai-sdk-nodejs-v4)

If you want to contribute SDKs for other languages to the official repository, feel free to submit a PR.
